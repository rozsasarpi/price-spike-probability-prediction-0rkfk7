# ERCOT RTLMP Spike Prediction System
# Model Training Configuration
# 
# This configuration file defines the parameters for training machine learning models
# to predict price spikes in the ERCOT Real-Time Locational Marginal Price (RTLMP) market.
# It is used by the Model Training Module to configure model types, training parameters,
# and evaluation metrics.

# Data selection and preprocessing configuration
data:
  # Time range for training data
  start_date: '2020-01-01'
  end_date: '2023-06-30'
  
  # Nodes to include in training
  nodes: 
    - 'HB_NORTH'
    - 'HB_SOUTH'
    - 'HB_WEST'
    - 'HB_HOUSTON'
  
  # Price threshold for spike definition ($/MWh)
  threshold: 100.0
  
  # Feature groups to include
  feature_groups:
    - 'time'
    - 'statistical'
    - 'weather'
    - 'market'
  
  # Data preprocessing configuration
  preprocessing:
    # Missing value imputation
    imputation:
      enabled: true
      method: 'median'
    
    # Feature scaling
    scaling:
      enabled: true
      method: 'standard'
      # Categorical features to exclude from scaling
      exclude_columns:
        - 'hour_of_day'
        - 'day_of_week'
        - 'month'
        - 'is_weekend'
        - 'is_holiday'
    
    # Feature selection
    feature_selection:
      enabled: true
      method: 'importance_threshold'
      importance_threshold: 0.005
      max_features: 100
  
  # Target variable configuration
  target:
    column: 'spike_occurred'
    definition: 'max_price_exceeds_threshold'
    lookforward_window: '1H'

# Model configuration
model:
  # Primary model type
  type: 'xgboost'
  
  # Hyperparameters for XGBoost
  hyperparameters:
    learning_rate: 0.05
    max_depth: 6
    min_child_weight: 1
    subsample: 0.8
    colsample_bytree: 0.8
    n_estimators: 200
    objective: 'binary:logistic'
    eval_metric: 'auc'
    use_label_encoder: false
    tree_method: 'hist'
    random_state: 42
  
  # Alternative models
  alternatives:
    # LightGBM configuration
    lightgbm:
      enabled: false
      hyperparameters:
        learning_rate: 0.05
        num_leaves: 31
        max_depth: -1
        min_data_in_leaf: 20
        feature_fraction: 0.8
        bagging_fraction: 0.8
        bagging_freq: 5
        objective: 'binary'
        metric: 'auc'
        boosting_type: 'gbdt'
        verbosity: -1
        random_state: 42
    
    # Ensemble model configuration
    ensemble:
      enabled: false
      base_models:
        - 'xgboost'
        - 'lightgbm'
      weights:
        - 0.5
        - 0.5
      voting: 'soft'

# Training process configuration
training:
  # Test set size for initial train/test split
  test_size: 0.2
  random_state: 42
  
  # Early stopping configuration
  early_stopping:
    enabled: true
    rounds: 50
    validation_ratio: 0.2
  
  # Cross-validation configuration
  cross_validation:
    enabled: true
    n_splits: 5
    strategy: 'time_series_split'
    max_train_size: null
    test_size: null
    gap: 0
  
  # Model retraining configuration
  retraining:
    schedule: 'every_2_days'
    min_data_points: 1000
    compare_with_previous: true
    min_improvement_threshold: 0.01
  
  # Number of parallel jobs for training
  parallel_jobs: 4

# Model evaluation configuration
evaluation:
  # Performance metrics
  metrics:
    primary: 'auc'
    secondary:
      - 'brier_score'
      - 'precision'
      - 'recall'
      - 'f1'
    # Probability thresholds for classification metrics
    thresholds:
      - 0.1
      - 0.2
      - 0.3
      - 0.4
      - 0.5
      - 0.6
      - 0.7
      - 0.8
      - 0.9
  
  # Probability calibration
  calibration:
    enabled: true
    n_bins: 10
    strategy: 'isotonic'
  
  # Feature importance calculation
  feature_importance:
    enabled: true
    method: 'permutation'
    n_repeats: 10
  
  # Validation strategy
  validation:
    strategy: 'time_based'
    n_splits: 5
    gap: 0

# Hyperparameter tuning configuration
hyperparameter_tuning:
  enabled: true
  method: 'bayesian'
  n_iterations: 50
  cv_folds: 5
  cv_strategy: 'time_series_split'
  scoring: 'auc'
  random_state: 42
  parallel_jobs: 4
  
  # Early stopping for hyperparameter search
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.001
  
  # Parameter grid for hyperparameter search
  param_grid:
    # XGBoost parameter grid
    xgboost:
      learning_rate:
        - 0.01
        - 0.05
        - 0.1
        - 0.2
      max_depth:
        - 3
        - 4
        - 5
        - 6
        - 8
        - 10
      min_child_weight:
        - 1
        - 3
        - 5
        - 7
      subsample:
        - 0.6
        - 0.7
        - 0.8
        - 0.9
      colsample_bytree:
        - 0.6
        - 0.7
        - 0.8
        - 0.9
      n_estimators:
        - 100
        - 200
        - 300
        - 500
    
    # LightGBM parameter grid
    lightgbm:
      learning_rate:
        - 0.01
        - 0.05
        - 0.1
        - 0.2
      num_leaves:
        - 20
        - 31
        - 50
        - 80
        - 100
      max_depth:
        - -1
        - 5
        - 10
        - 15
        - 20
      min_data_in_leaf:
        - 10
        - 20
        - 30
        - 50
      feature_fraction:
        - 0.6
        - 0.7
        - 0.8
        - 0.9
      bagging_fraction:
        - 0.6
        - 0.7
        - 0.8
        - 0.9
      bagging_freq:
        - 0
        - 5
        - 10
      n_estimators:
        - 100
        - 200
        - 300
        - 500

# Output configuration
output:
  # Path for storing trained models
  model_registry_path: '${paths.model_dir}'
  # Format for model version naming
  version_format: '%Y%m%d_%H%M%S'
  
  # What to save alongside the model
  save_feature_importance: true
  save_evaluation_metrics: true
  save_cross_validation_results: true
  save_hyperparameter_tuning_results: true
  
  # Model metadata
  metadata:
    include_data_summary: true
    include_feature_list: true
    include_hyperparameters: true
    include_training_time: true
  
  # Export configuration
  export:
    # Feature importance visualization
    feature_importance_plot:
      enabled: true
      format:
        - 'png'
        - 'html'
      path: '${paths.output_dir}/feature_importance'
    
    # Evaluation report
    evaluation_report:
      enabled: true
      format:
        - 'json'
        - 'html'
      path: '${paths.output_dir}/evaluation'