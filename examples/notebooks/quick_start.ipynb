{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: ERCOT RTLMP Spike Prediction System\n",
    "\n",
    "This notebook provides a quick start guide for the ERCOT RTLMP spike prediction system. It demonstrates the core functionality including data fetching, feature engineering, model training, and inference with visualizations.\n",
    "\n",
    "**System Overview**\n",
    "\n",
    "The ERCOT RTLMP spike prediction system forecasts the probability of price spikes in the Real-Time Locational Marginal Price (RTLMP) market before day-ahead market closure. Energy storage operators need accurate predictions of potential price spikes to optimize battery charging/discharging strategies and maximize revenue.\n",
    "\n",
    "**Key Features**\n",
    "\n",
    "*   Daily inference runs before day-ahead market closure\n",
    "*   72-hour forecast horizon starting from the day after DAM closure\n",
    "*   Probability predictions for each hour in the forecast horizon\n",
    "*   Modular code structure with clearly defined interfaces\n",
    "*   Retraining capability on a two-day cadence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Structure\n",
    "\n",
    "1.  **Setup and Imports**: Import necessary libraries and set up the environment.\n",
    "2.  **Data Fetching**: Retrieve RTLMP and grid condition data from ERCOT.\n",
    "3.  **Feature Engineering**: Transform raw data into model-ready features.\n",
    "4.  **Model Training**: Train an XGBoost model to predict price spikes.\n",
    "5.  **Inference**: Generate price spike probability forecasts.\n",
    "6.  **Visualization**: Visualize forecast results.\n",
    "7.  **Conclusion**: Summary and next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External libraries\n",
    "import pandas as pd  # version 2.0+\n",
    "import numpy as np  # version 1.24+\n",
    "import matplotlib.pyplot as plt  # version 3.7+\n",
    "import seaborn as sns  # version 0.12+\n",
    "import plotly.express as px  # version 5.14+\n",
    "import datetime  # Standard\n",
    "from sklearn.model_selection import train_test_split  # scikit-learn version 1.2+\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, precision_score, recall_score, f1_score  # scikit-learn version 1.2+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import internal modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal modules\n",
    "from src.backend.data.fetchers.ercot_api import ERCOTDataFetcher  # src/backend/data/fetchers/ercot_api.py\n",
    "from src.backend.features.feature_pipeline import FeaturePipeline, DEFAULT_FEATURE_CONFIG  # src/backend/features/feature_pipeline.py\n",
    "from src.backend.models.xgboost_model import XGBoostModel  # src/backend/models/xgboost_model.py\n",
    "from src.backend.inference.engine import InferenceEngine  # src/backend/inference/engine.py\n",
    "from src.backend.config.schema import InferenceConfig  # src/backend/config/schema.py\n",
    "from src.backend.visualization.forecast_plots import ForecastPlotter  # src/backend/visualization/forecast_plots.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "PRICE_SPIKE_THRESHOLD = 100.0  # $/MWh\n",
    "FORECAST_HORIZON = 72  # hours\n",
    "DEFAULT_NODES = ['HB_NORTH', 'HB_SOUTH', 'HB_WEST', 'HB_HOUSTON']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates how to fetch RTLMP and grid condition data from ERCOT using the `ERCOTDataFetcher` class. The data is fetched for a specified date range and node locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ERCOTDataFetcher\n",
    "data_fetcher = ERCOTDataFetcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch historical RTLMP data\n",
    "start_date = datetime.datetime(2023, 1, 1)\n",
    "end_date = datetime.datetime(2023, 1, 10)\n",
    "rtlmp_df = data_fetcher.fetch_historical_data(start_date, end_date, DEFAULT_NODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch grid condition data\n",
    "grid_start_date = datetime.datetime(2023, 1, 1)\n",
    "grid_end_date = datetime.datetime(2023, 1, 10)\n",
    "grid_df = data_fetcher.fetch_historical_data(grid_start_date, grid_end_date, identifiers=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "print(\"RTLMP Data:\")\n",
    "print(rtlmp_df.head())\n",
    "\n",
    "print(\"\\nGrid Condition Data:\")\n",
    "print(grid_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain feature engineering process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates how to transform raw data into model-ready features using the `FeaturePipeline` class. The pipeline includes time-based, statistical, weather, and market features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FeaturePipeline\n",
    "feature_pipeline = FeaturePipeline(DEFAULT_FEATURE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data sources to the pipeline\n",
    "feature_pipeline.add_data_source('rtlmp_df', rtlmp_df)\n",
    "feature_pipeline.add_data_source('grid_df', grid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "features_df = feature_pipeline.create_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display engineered features\n",
    "print(\"Engineered Features:\")\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the modeling approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates how to train an XGBoost model to predict price spikes. The data is split into training and testing sets, and the model is trained using the training data. The model performance is then evaluated using the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable\n",
    "def create_target_variable(rtlmp_df: pd.DataFrame, threshold: float) -> pd.Series:\n",
    "    \"\"\"Creates a binary target variable indicating whether a price spike occurred\"\"\"\n",
    "    # Group RTLMP data by hour\n",
    "    hourly_data = rtlmp_df.groupby(rtlmp_df['timestamp'].dt.floor('H'))\n",
    "    \n",
    "    # For each hour, check if any 5-minute price exceeds the threshold\n",
    "    def check_spike(group):\n",
    "        return (group['price'] > threshold).any()\n",
    "    \n",
    "    # Create a binary indicator (1 if spike occurred, 0 otherwise)\n",
    "    target_series = hourly_data.apply(check_spike)\n",
    "    \n",
    "    # Return the binary target series\n",
    "    return target_series\n",
    "\n",
    "target = create_target_variable(rtlmp_df, PRICE_SPIKE_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X = features_df.drop(columns=['timestamp', 'node_id'], errors='ignore') # Drop non-feature columns\n",
    "y = target.astype(int)  # Convert target to int\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train XGBoostModel\n",
    "model = XGBoostModel(model_id='rtlmp_spike_model', hyperparameters={'objective': 'binary:logistic', 'eval_metric': 'logloss'}) # Specify objective and evaluation metric\n",
    "model.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "def evaluate_forecast(forecast_df: pd.DataFrame, actual_df: pd.DataFrame, threshold: float) -> dict:\n",
    "    \"\"\"Evaluates the forecast against actual values\"\"\"\n",
    "    # Align forecast and actual data by timestamp\n",
    "    merged_data = pd.merge(forecast_df, actual_df, left_index=True, right_index=True, suffixes=('_forecast', '_actual'))\n",
    "    \n",
    "    # Calculate AUC-ROC score\n",
    "    auc_roc = roc_auc_score(merged_data['spike_occurred'], merged_data['spike_probability'])\n",
    "    \n",
    "    # Calculate Brier score\n",
    "    brier_score = brier_score_loss(merged_data['spike_occurred'], merged_data['spike_probability'])\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    y_pred = (merged_data['spike_probability'] > 0.5).astype(int)\n",
    "    precision = precision_score(merged_data['spike_occurred'], y_pred)\n",
    "    recall = recall_score(merged_data['spike_occurred'], y_pred)\n",
    "    f1 = f1_score(merged_data['spike_occurred'], y_pred)\n",
    "    \n",
    "    # Return dictionary with all metrics\n",
    "    return {\n",
    "        'auc_roc': auc_roc,\n",
    "        'brier_score': brier_score,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "performance_metrics = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "importance = model.get_feature_importance()\n",
    "importance_df = pd.DataFrame({\"Feature\": importance.keys(), \"Importance\": importance.values()})\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=importance_df.sort_values(by=\"Importance\", ascending=False))\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the inference process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates how to generate price spike probability forecasts using the `InferenceEngine` class. The inference engine loads the trained model and generates a 72-hour forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize InferenceEngine with configuration\n",
    "inference_config = InferenceConfig(thresholds=[PRICE_SPIKE_THRESHOLD])\n",
    "inference_engine = InferenceEngine(config=inference_config)\n",
    "\n",
    "# Load the trained model\n",
    "inference_engine.load_model(model_id='rtlmp_spike_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 72-hour forecast\n",
    "forecast_start_date = datetime.datetime(2023, 1, 11)\n",
    "forecast_data_sources = {\n",
    "    'rtlmp_df': rtlmp_df,\n",
    "    'grid_df': grid_df\n",
    "}\n",
    "forecast_df = inference_engine.run_inference(forecast_data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display forecast results\n",
    "print(\"Forecast Results:\")\n",
    "print(forecast_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain visualization options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates how to visualize the forecast results using the `ForecastPlotter` class. The visualizations include a probability timeline plot and a threshold comparison plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ForecastPlotter\n",
    "plotter = ForecastPlotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load forecast data\n",
    "plotter.load_forecast(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create probability timeline plot\n",
    "fig_timeline, ax_timeline = plotter.plot_probability_timeline()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create threshold comparison plot\n",
    "fig_comparison, ax_comparison = plotter.plot_threshold_comparison()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive dashboard\n",
    "fig_dashboard = plotter.create_forecast_dashboard()\n",
    "fig_dashboard.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export visualizations\n",
    "# plotter.save_plot(fig_timeline, 'probability_timeline.png')\n",
    "# plotter.save_plot(fig_comparison, 'threshold_comparison.png')\n",
    "# plotter.save_interactive_plot(fig_dashboard, 'forecast_dashboard.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of what was learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrated the core functionality of the ERCOT RTLMP spike prediction system, including data fetching, feature engineering, model training, inference, and visualization. This provides a foundation for further exploration and customization of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps for exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Experiment with different feature engineering techniques.\n",
    "2.  Explore different machine learning models and hyperparameter tuning.\n",
    "3.  Implement more sophisticated visualization techniques.\n",
    "4.  Integrate the system with real-time data sources and battery optimization workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   [ERCOT Data API Documentation](https://www.ercot.com/services/data)\n",
    "*   [XGBoost Documentation](https://xgboost.readthedocs.io/en/stable/)\n",
    "*   [Scikit-learn Documentation](https://scikit-learn.org/stable/)\n",
    "*   See other notebooks in the `examples/notebooks` directory for more detailed examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbreg": {
   "version": {
    "major": 0,
    "minor": 0,
    "patch": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}